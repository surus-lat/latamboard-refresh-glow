export type Locale = 'en' | 'es' | 'pt'

export const DEFAULT_LOCALE: Locale = 'en'

export type TranslationDict = Record<string, string | TranslationDict>

export const en: TranslationDict = {
  common: {
    app_name: 'LATAM Leaderboard',
    home: 'Home',
    tasks: 'Tasks',
    about: 'About',
    submit: 'Submit',
    our_website: 'Our Website',
    join_discord: 'Join our Discord',
    contact_email: 'contacto@surus.dev',
    loading: 'Loading…',
    error_generic: 'Something went wrong. Try again.',
  },
  landing: {
    hero_title: 'LATAM Leaderboard',
    hero_subtitle:
      "The community-driven platform for evaluating AI models on Spanish and Portuguese benchmarks. Advancing AI excellence across Latin America through transparent, rigorous evaluation.",
    source_prefix: 'Source:',
    source_link: 'Hugging Face dataset',
    load_failed: 'Failed to load leaderboard data',
    columns: {
      model_name: 'model_name',
      overall_latam_score: 'overall_latam_score',
      spanish_score: 'spanish_score',
      portuguese_score: 'portuguese_score',
    },
  },
  tests: {
    title: 'Tasks',
    loading: 'Loading tasks…',
    repo: 'Repository',
    key: 'Key',
    shots: 'shots',
    failed_meta: 'Failed to load tasks metadata',
    dataset: 'Dataset',
  },
  submit: {
    suggest_model: 'Suggest a Model',
    model_name: 'Model name',
    precision: 'Precision',
    email: 'Email',
    model_placeholder: 'org/model',
    precision_placeholder: 'e.g. bf16, fp8',
    email_placeholder: 'you@example.com',
    submit: 'Submit',
    submitting: 'Submitting…',
    thanks_touch: "Thanks! We'll be in touch.",
    thanks_review: "Thanks! We'll review it.",
    suggest_task: 'Suggest a Task/Dataset',
    task_key: 'Task key',
    task_name: 'Task name',
    group: 'Category / Group',
    select: 'Select…',
    spanish_group: 'Spanish (latam_es)',
    portuguese_group: 'Portuguese (latam_pr)',
    other_group: 'Other (latam_ts)',
    dataset_url: 'Dataset URL',
    url_placeholder: 'https://huggingface.co/datasets/...',
    short_desc: 'Short description',
    short_desc_placeholder: 'What does this task evaluate?',
    contact_email_label: 'Contact email',
    submit_task: 'Submit task',
    not_sure: 'Not sure how to start?',
    get_in_touch: 'Get in touch',
  },
  about: {
    title: 'About LATAM Leaderboard',
    p1:
      "LATAM Leaderboard is a community initiative dedicated to establishing task-oriented, transparent evaluation standards for AI systems serving Latin America. We're helping build the engine to measure real work, not just language fluency.",
    p2:
      "LATAM Leaderboard is more than a ranking system, it's the foundation for establishing our region as a global AI innovation hub. Whether you're a researcher, developer, or AI enthusiast, there's a place for you in building these evaluation standards.",
    mission_title: 'Our Mission',
    mission_p:
      'We create rigorous, region-specific, task-oriented benchmarks, in Spanish and Portuguese and across LATAM industries, so researchers, developers, and companies can train, choose, and ship models that actually move the needle in production.',
    why_title: 'Why This Matters',
    culture_sub: 'From Culture to Capability',
    culture_p1:
      "AI evaluation has been dominated by English-centric benchmarks that fail to capture the nuanced performance requirements of Latin American markets. We're changing that by creating rigorous, region-specific evaluation standards that empower our community to build and choose AI solutions with confidence.",
    culture_p2:
      "Capturing regional idiosyncrasies is essential but not sufficient. The main bottleneck is evaluation: without precise, task-level signals, models can't reliably learn instructions, follow constraints, or deliver production outcomes.",
    signals_sub: 'Signals for Learning (and RL)',
    signals_p:
      'As training shifts toward reinforcement and feedback-driven methods, we need clear, auditable success criteria. Our benchmarks are designed so their results can serve as training/validation signals—making "what good looks like" explicit for LATAM tasks.',
    bridge_sub: 'Bridging the Evaluation Gap',
    bridge_p:
      "High-quality evaluations in Spanish and Portuguese are scarce, especially for concrete tasks. That gap blocks informed decisions and slows model progress for real LATAM use cases.",
    how_title: 'How We Evaluate Models',
    how_p: 'We run publicly accessible benchmarks based on multiple forks of lm-evaluation-harness, focusing on:',
    how_li1: 'Task definitions with acceptance criteria (what counts as success).',
    how_li2: 'Reproducible setups (versioned configs, seeds, and data).',
    how_li3: 'Outcome-first scoring (task success plus supporting metrics appropriate to each task).',
    how_li4: "Transparent reports (what the benchmark covers—and what it doesn't).",
    evolving_title: 'Evolving Standards',
    evolving_li1: 'Phase 1: Comprehensive language understanding benchmarks.',
    evolving_li2:
      'Phase 2: Real-world task evaluation (e.g., translation, transcription, summarization, instruction following, and structured outputs).',
    evolving_li3:
      'Phase 3: Community-contributed benchmarks and specialized datasets, with feedback formats suitable for training and RL workflows.',
    community_title: 'Community Collaboration',
    aips_sub: 'For AI Product Managers (AI PMs)',
    aips_p: 'Translate business outcomes into benchmarks and training signals. Define what "good" means so models can be steered toward real KPIs.',
    research_sub: 'For Researchers & Universities',
    research_p: 'Contribute benchmarks, methodologies, and datasets. Help set academic standards that align with real regional needs.',
    devs_sub: 'For Model Developers',
    devs_p:
      'Showcase model performance on region-specific tasks. Get actionable insight into strengths, weaknesses, and where to focus further training.',
    companies_sub: 'For Companies & Practitioners',
    companies_p:
      'Access reliable performance data to guide implementation. Propose your actual tasks—we\'ll help express them as clear benchmarks with acceptance criteria.',
    commit_title: 'Our Commitment',
    commit_li1: 'Open Science: Benchmarks, code, and results are public by default.',
    commit_li2: 'Academic Rigor: Transparent methodology and careful scope—no leaderboard theater.',
    commit_li3: 'Regional Focus: Built around LATAM languages and the tasks that drive productivity.',
    commit_li4: 'Community Ownership: We maintain the infrastructure; the community shapes the standards.',
    future_title: "Help Build Latin America's AI Future",
    future_p:
      "LATAM Leaderboard is more than a ranking, it's the evaluation layer that lets our region train and deploy systems that solve real problems.",
    ready_title: 'Ready to contribute?',
    ready_p:
      'LATAM Leaderboard is proudly supported by compute infrastructure from Surus, with development and methodology contributions from the broader LATAM AI community.',
  },
}

export const es: TranslationDict = {
  common: {
    app_name: 'LATAM Leaderboard',
    home: 'Inicio',
    tasks: 'Tareas',
    about: 'Acerca de',
    submit: 'Enviar',
    our_website: 'Nuestro sitio web',
    join_discord: 'Únete a nuestro Discord',
    contact_email: 'contacto@surus.dev',
    loading: 'Cargando…',
    error_generic: 'Algo salió mal. Intenta de nuevo.',
  },
  landing: {
    hero_title: 'LATAM Leaderboard',
    hero_subtitle:
      'Plataforma comunitaria para evaluar modelos de IA en español y portugués. Impulsando la excelencia en IA en América Latina con evaluación rigurosa y transparente.',
    source_prefix: 'Fuente:',
    source_link: 'Dataset en Hugging Face',
    load_failed: 'Error al cargar los datos del leaderboard',
    columns: {
      model_name: 'model_name',
      overall_latam_score: 'overall_latam_score',
      spanish_score: 'spanish_score',
      portuguese_score: 'portuguese_score',
    },
  },
  tests: {
    title: 'Tareas',
    loading: 'Cargando tareas…',
    repo: 'Repositorio',
    key: 'Clave',
    shots: 'disparos',
    failed_meta: 'Error al cargar los metadatos de tareas',
    dataset: 'Dataset',
  },
  submit: {
    suggest_model: 'Sugerir un modelo',
    model_name: 'Nombre del modelo',
    precision: 'Precisión',
    email: 'Correo electrónico',
    model_placeholder: 'org/model',
    precision_placeholder: 'p. ej., bf16, fp8',
    email_placeholder: 'tu@ejemplo.com',
    submit: 'Enviar',
    submitting: 'Enviando…',
    thanks_touch: '¡Gracias! Nos pondremos en contacto.',
    thanks_review: '¡Gracias! Lo revisaremos.',
    suggest_task: 'Sugerir una tarea/dataset',
    task_key: 'Clave de la tarea',
    task_name: 'Nombre de la tarea',
    group: 'Categoría / Grupo',
    select: 'Seleccionar…',
    spanish_group: 'Español (latam_es)',
    portuguese_group: 'Portugués (latam_pr)',
    other_group: 'Otro (latam_ts)',
    dataset_url: 'URL del dataset',
    url_placeholder: 'https://huggingface.co/datasets/...',
    short_desc: 'Descripción breve',
    short_desc_placeholder: '¿Qué evalúa esta tarea?',
    contact_email_label: 'Correo de contacto',
    submit_task: 'Enviar tarea',
    not_sure: '¿No sabes por dónde empezar?',
    get_in_touch: 'Contáctanos',
  },
  about: {
    title: 'Sobre LATAM Leaderboard',
    p1:
      "LATAM Leaderboard es una iniciativa comunitaria dedicada a establecer estándares de evaluación transparentes y orientados a tareas para sistemas de IA en América Latina. Estamos ayudando a construir un motor que mide trabajo real, no solo fluidez lingüística.",
    p2:
      "LATAM Leaderboard es más que un sistema de rankings, es la base para posicionar a nuestra región como un hub global de innovación en IA. Seas investigador, desarrollador o entusiasta de la IA, hay un lugar para vos en la construcción de estos estándares de evaluación.",
    mission_title: 'Nuestra Misión',
    mission_p:
      'Creamos benchmarks rigurosos, específicos para la región y orientados a tareas, en español y portugués y a través de industrias de LATAM, para que investigadores, desarrolladores y empresas puedan entrenar, elegir y desplegar modelos que realmente marquen la diferencia en producción.',
    why_title: 'Por qué Importa',
    culture_sub: 'De la Cultura a la Capacidad',
    culture_p1:
      "La evaluación en IA ha estado dominada por benchmarks centrados en el inglés que no capturan los requisitos de desempeño matizados de los mercados latinoamericanos.",
    culture_p2:
      "Estamos cambiando eso al crear estándares rigurosos y específicos para la región que empoderan a nuestra comunidad a construir y elegir soluciones de IA con confianza.",
    signals_sub: 'Señales para el Aprendizaje (y RL)',
    signals_p:
      'Capturar las idiosincrasias regionales es esencial, pero no suficiente. El principal cuello de botella es la evaluación en aplicaciones reales: sin señales precisas a nivel de tarea, los modelos no pueden aprender de forma confiable, seguir restricciones o entregar resultados productivos. A medida que el entrenamiento se desplaza hacia métodos de refuerzo y basados en retroalimentación, necesitamos criterios de éxito claros y auditables. Nuestros benchmarks están diseñados para que sus resultados sirvan como señales de entrenamiento/validación, haciendo explícito qué representa “hacerlo bien” en tareas de LATAM.',
    bridge_sub: 'Cerrando la Brecha de Evaluación',
    bridge_p:
      "Las evaluaciones de alta calidad en español y portugués son escasas, especialmente para tareas concretas. Esa brecha bloquea decisiones informadas y ralentiza el progreso de los modelos en casos de uso reales de LATAM.",
    how_title: 'Cómo Evaluamos Modelos',
    how_p: 'Ejecutamos benchmarks de acceso público basados en múltiples forks de lm-evaluation-harness, con foco en:',
    how_li1: 'Definiciones de tareas con criterios de aceptación (qué cuenta como éxito).',
    how_li2: 'Entornos reproducibles (configs versionadas, semillas y datos).',
    how_li3: 'Evaluación orientada a resultados (éxito en la tarea más métricas de apoyo apropiadas para cada caso).',
    how_li4: "Reportes transparentes (qué cubre el benchmark, y qué no).",
    evolving_title: 'Estándares en Evolución',
    evolving_li1: 'Fase 1: Benchmarks integrales de comprensión del lenguaje.',
    evolving_li2:
      'Fase 2: Evaluación de tareas del mundo real (ej. traducción, transcripción, resumen, seguimiento de instrucciones y salidas estructuradas).',
    evolving_li3:
      'Fase 3: Benchmarks y datasets especializados aportados por la comunidad, con formatos de retroalimentación adecuados para entrenamiento y flujos de RL.',
    community_title: 'Colaboración Comunitaria',
    aips_sub: 'Para Product Managers de IA (AI PMs)',
    aips_p: 'Traducir resultados de negocio en benchmarks y señales de entrenamiento. Definir qué significa “bueno” para guiar los modelos hacia KPIs reales.',
    research_sub: 'Para Investigadores y Universidades',
    research_p: 'Contribuir con benchmarks, metodologías y datasets. Ayudar a establecer estándares académicos alineados con necesidades reales de la región.',
    devs_sub: 'Para Desarrolladores de Modelos',
    devs_p:
      'Mostrar el desempeño de los modelos en tareas específicas de la región. Obtener información accionable sobre fortalezas, debilidades y dónde enfocar más entrenamiento.',
    companies_sub: 'Para Empresas y Profesionales',
    companies_p:
      'Acceder a datos de desempeño confiables para guiar la implementación. Proponer tus tareas reales: te ayudamos a expresarlas como benchmarks claros con criterios de aceptación.',
    commit_title: 'Nuestro Compromiso',
    commit_li1: 'Ciencia Abierta: Benchmarks, código y resultados son públicos por defecto.',
    commit_li2: 'Rigor Académico: Metodología transparente y alcance cuidadoso—sin “teatro de leaderboards”.',
    commit_li3: 'Enfoque Regional: Construido alrededor de los idiomas y tareas de LATAM que impulsan la productividad.',
    commit_li4: 'Propiedad Comunitaria: Mantenemos la infraestructura; la comunidad define los estándares.',
    future_title: "Ayudá a Construir el Futuro de la IA en LATAM",
    future_p:
      "LATAM Leaderboard es más que un ranking, es la capa de evaluación que permite a nuestra región entrenar y desplegar sistemas que resuelvan problemas reales.",
    ready_title: '¿Listo para contribuir?',
    ready_p:
      'LATAM Leaderboard cuenta con el apoyo de infraestructura de cómputo de Surus, junto con contribuciones de desarrollo y metodología de la comunidad de IA de LATAM.',
  },
}

export const pt: TranslationDict = {
  common: {
    app_name: 'LATAM Leaderboard',
    home: 'Início',
    tasks: 'Tarefas',
    about: 'Sobre',
    submit: 'Enviar',
    our_website: 'Nosso site',
    join_discord: 'Entre no nosso Discord',
    contact_email: 'contacto@surus.dev',
    loading: 'Carregando…',
    error_generic: 'Algo deu errado. Tente novamente.',
  },
  landing: {
    hero_title: 'LATAM Leaderboard',
    hero_subtitle:
      'Plataforma comunitária para avaliar modelos de IA em espanhol e português. Promovendo excelência em IA na América Latina com avaliação rigorosa e transparente.',
    source_prefix: 'Fonte:',
    source_link: 'Dataset no Hugging Face',
    load_failed: 'Falha ao carregar os dados do leaderboard',
    columns: {
      model_name: 'model_name',
      overall_latam_score: 'overall_latam_score',
      spanish_score: 'spanish_score',
      portuguese_score: 'portuguese_score',
    },
  },
  tests: {
    title: 'Tarefas',
    loading: 'Carregando tarefas…',
    repo: 'Repositório',
    key: 'Chave',
    shots: 'exemplos',
    failed_meta: 'Falha ao carregar metadados das tarefas',
    dataset: 'Dataset',
  },
  submit: {
    suggest_model: 'Sugerir um modelo',
    model_name: 'Nome do modelo',
    precision: 'Precisão',
    email: 'E-mail',
    model_placeholder: 'org/model',
    precision_placeholder: 'ex.: bf16, fp8',
    email_placeholder: 'voce@exemplo.com',
    submit: 'Enviar',
    submitting: 'Enviando…',
    thanks_touch: 'Obrigado! Entraremos em contato.',
    thanks_review: 'Obrigado! Iremos revisar.',
    suggest_task: 'Sugerir tarefa/dataset',
    task_key: 'Chave da tarefa',
    task_name: 'Nome da tarefa',
    group: 'Categoria / Grupo',
    select: 'Selecionar…',
    spanish_group: 'Espanhol (latam_es)',
    portuguese_group: 'Português (latam_pr)',
    other_group: 'Outro (latam_ts)',
    dataset_url: 'URL do dataset',
    url_placeholder: 'https://huggingface.co/datasets/...',
    short_desc: 'Descrição breve',
    short_desc_placeholder: 'O que esta tarefa avalia?',
    contact_email_label: 'E-mail de contato',
    submit_task: 'Enviar tarefa',
    not_sure: 'Sem saber por onde começar?',
    get_in_touch: 'Fale conosco',
  },
  about: {
    title: 'Sobre o LATAM Leaderboard',
    p1:
      'O LATAM Leaderboard é uma iniciativa comunitária dedicada a estabelecer padrões de avaliação orientados a tarefas e transparentes para sistemas de IA na América Latina. Medimos trabalho real, não apenas fluência.',
    p2:
      'Mais que um ranking, é a base para tornar a região um polo global de inovação em IA. Pesquisadores, desenvolvedores e entusiastas são bem-vindos para construir esses padrões.',
    mission_title: 'Nossa missão',
    mission_p:
      'Criamos benchmarks rigorosos, regionais e orientados a tarefas, em espanhol e português e em setores da LATAM, para que modelos sejam treinados e escolhidos com impacto real.',
    why_title: 'Por que isso importa',
    culture_sub: 'Da cultura à capacidade',
    culture_p1:
      'A avaliação em IA é dominada por benchmarks em inglês que não capturam as necessidades latino-americanas. Estamos mudando isso com padrões rigorosos e regionais.',
    culture_p2:
      'Capturar especificidades regionais é essencial, mas não basta. O gargalo é a avaliação: sem sinais claros por tarefa, modelos não seguem instruções nem entregam resultados.',
    signals_sub: 'Sinais para aprendizado (e RL)',
    signals_p:
      'Com o avanço de métodos baseados em reforço e feedback, precisamos de critérios de sucesso auditáveis. Nossos benchmarks podem servir de sinais de treino/validação.',
    bridge_sub: 'Reduzindo a lacuna de avaliação',
    bridge_p:
      'Faltam avaliações de qualidade em espanhol e português, sobretudo para tarefas concretas. Isso dificulta decisões e o progresso.',
    how_title: 'Como avaliamos modelos',
    how_p: 'Executamos benchmarks públicos baseados em forks do lm-evaluation-harness, focando em:',
    how_li1: 'Definições de tarefa com critérios de aceitação.',
    how_li2: 'Configurações reprodutíveis (versionamento, seeds e dados).',
    how_li3: 'Métricas orientadas ao resultado.',
    how_li4: 'Relatórios transparentes (o que cobre e o que não).',
    evolving_title: 'Padrões em evolução',
    evolving_li1: 'Fase 1: compreensão de linguagem.',
    evolving_li2: 'Fase 2: tarefas do mundo real (tradução, transcrição, resumo, instruções e saídas estruturadas).',
    evolving_li3: 'Fase 3: benchmarks da comunidade e datasets especializados, com formatos úteis para treino e RL.',
    community_title: 'Colaboração da comunidade',
    aips_sub: 'Para PMs de IA',
    aips_p: 'Traduza resultados de negócio em benchmarks e sinais de treinamento.',
    research_sub: 'Para pesquisadores e universidades',
    research_p: 'Contribua com benchmarks, metodologias e datasets alinhados às necessidades reais.',
    devs_sub: 'Para desenvolvedores de modelos',
    devs_p: 'Mostre desempenho em tarefas regionais e obtenha insights acionáveis.',
    companies_sub: 'Para empresas e profissionais',
    companies_p: 'Acesse dados confiáveis para guiar implementações. Proponha suas tarefas reais.',
    commit_title: 'Nosso compromisso',
    commit_li1: 'Ciência aberta: benchmarks, código e resultados públicos.',
    commit_li2: 'Rigor acadêmico: metodologia transparente; sem encenação.',
    commit_li3: 'Foco regional: línguas e tarefas que geram produtividade.',
    commit_li4: 'Protagonismo comunitário: a comunidade define os padrões.',
    future_title: 'Ajude a construir o futuro da IA na LATAM',
    future_p: 'Mais que ranking, somos a camada de avaliação para soluções reais.',
    ready_title: 'Pronto para contribuir?',
    ready_p: 'Com apoio de infraestrutura da Surus e da comunidade LATAM de IA.',
  },
}

export const translations: Record<Locale, TranslationDict> = { en, es, pt }


