export function About() {
  return (
    <div className="container prose prose-neutral max-w-3xl py-10">
      <h1>About LATAM Leaderboard</h1>
      <p>
        LATAM Leaderboard is a community initiative dedicated to establishing comprehensive, transparent evaluation standards for AI models across Spanish and Portuguese language tasks. We're building the benchmarking infrastructure that Latin America's AI ecosystem deserves.
      </p>

      <h2>Our Mission</h2>
      <p>
        AI evaluation has been dominated by English-centric benchmarks that fail to capture the nuanced performance requirements of Latin American markets. We're changing that by creating rigorous, region-specific evaluation standards that empower our community to build and choose AI solutions with confidence.
      </p>

      <h2>Why This Matters</h2>
      <h3>Bridging the Evaluation Gap</h3>
      <p>
        High-quality evaluations in Spanish and Portuguese are scarce, making it difficult for developers, researchers, and companies to make informed decisions about AI models for their specific use cases.
      </p>
      <h3>Empowering Regional Innovation</h3>
      <p>
        By providing transparent performance metrics, we enable LATAM researchers and companies to compete on equal footing with global AI development, fostering local innovation and expertise.
      </p>
      <h3>Community-Driven Standards</h3>
      <p>
        We believe the best evaluation frameworks emerge from community collaboration. Our open approach ensures benchmarks reflect real regional needs.
      </p>

      <h2>How We Evaluate Models</h2>
      <p>We run publicly accessible benchmarks based on multiple forks of lm-evaluation-harness.</p>

      <h3>Evolving Standards</h3>
      <ul>
        <li>Phase 1: Comprehensive language understanding benchmarks</li>
        <li>Phase 2: Real-world task evaluation (translation, transcription, summarization)</li>
        <li>Phase 3: Community-contributed benchmarks and specialized datasets</li>
      </ul>

      <h2>Community Collaboration</h2>
      <h3>For Researchers &amp; Universities</h3>
      <p>
        Contribute new benchmarks, evaluation methodologies, and datasets. Help establish academic standards for LATAM AI evaluation while advancing your research visibility.
      </p>
      <h3>For Model Developers</h3>
      <p>
        Showcase your models' performance on region-specific tasks. Get detailed insights into strengths and areas for improvement across diverse Spanish and Portuguese use cases.
      </p>
      <h3>For Companies &amp; Practitioners</h3>
      <p>
        Access reliable performance data to guide your AI implementation decisions. Understand which models work best for your specific LATAM market requirements.
      </p>

      <h2>Our Commitment</h2>
      <ul>
        <li><strong>Open Science:</strong> All benchmarks, evaluation code, and results are publicly accessible. We believe progress comes through shared knowledge and transparent methodology.</li>
        <li><strong>Academic Rigor:</strong> We follow the standards set by universities and research institutions worldwide to ensure our evaluation standards meet the highest scientific criteria.</li>
        <li><strong>Regional Focus:</strong> LATAM Leaderboard is designed with Latin American contexts, languages, and business needs in mind.</li>
        <li><strong>Community Ownership:</strong> While we provide the infrastructure and initial development, LATAM Leaderboard belongs to the community that uses and improves it.</li>
      </ul>

      <h2>Help Build Latin America's AI Future</h2>
      <p>
        LATAM Leaderboard is more than a ranking system, it's the foundation for establishing our region as a global AI innovation hub. Whether you're a researcher, developer, or AI enthusiast, there's a place for you in building these evaluation standards.
      </p>
      <h3>Ways to Contribute:</h3>
      <h4>ðŸŽ“ Academic Partners</h4>
      <p>
        Universities and research institutions: Partner with us to develop new benchmarks and evaluation methodologies. Get early access to evaluation tools and contribute to cutting-edge AI research.
      </p>
      <h4>ðŸ”¬ Model Developers</h4>
      <p>
        Submit your models for evaluation and get detailed performance insights across regional tasks. Help set the standards for AI excellence in Latin America.
      </p>
      <h4>ðŸ“Š Dataset Contributors</h4>
      <p>
        Help us build comprehensive evaluation datasets that reflect real LATAM use cases. Contribute domain-specific data and evaluation scenarios.
      </p>
      <h4>ðŸ’» Technical Contributors</h4>
      <p>
        Contribute to our open-source evaluation infrastructure. Help improve our benchmarks, tools, and methodologies.
      </p>

      <h2>Ready to contribute?</h2>

      <p>
        LATAM Leaderboard is proudly supported by compute infrastructure from Surus, with development and methodology contributions from the broader LATAM AI community.
      </p>
    </div>
  )
}



